{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Simulation-Based Digital Twin: Nibelungenbrücke\n",
    "\n",
    "This notebook introduces an online simulation-based digital twin developed for the Nibelungenbrücke bridge. The orchestration system is designed to interact dynamically with the user by gathering key inputs; such as time, physical parameters, and spatial positions to perform real-time simulations of the bridge structure.\n",
    "\n",
    "The simulations are powered by the FenicSXConcrete package and support both thermomechanical and structural deflection analyses. This framework enables physics-based modeling and continuous digital monitoring of the bridge's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Please run the code below once to install the packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install git+https://github.com/BAMresearch/FenicsXConcrete pint gmsh pytest jsonschema pandas pyproj tqdm pvlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code snippet adjusts the current working directory and modifies the system path to ensure proper module resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "original_cwd = os.getcwd()\n",
    "root_dir = os.getcwd()\n",
    "orchestrator_dir = os.path.join(root_dir, 'nibelungenbruecke', 'scripts', 'digital_twin_orchestrator')\n",
    "os.chdir(orchestrator_dir)\n",
    "sys.path.insert(0, root_dir)\n",
    "\n",
    "from nibelungenbruecke.scripts.digital_twin_orchestrator.orchestrator import Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of input parameters\n",
    "\n",
    "This dictionary defines the configuration for running a digital twin simulation, including model selection, temporal settings, sensor definitions, and simulation options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_parameters = {\n",
    "    'simulation_name': 'TestSimulation',\n",
    "    'model': 'TransientThermal_1',\n",
    "    'start_time': '2023-08-11T08:00:00Z',\n",
    "    'end_time': '2023-09-11T08:01:00Z',\n",
    "    'time_step': '10min',\n",
    "    'parameter_update': {'rho': 2800, 'E': 310000000000},       ##TODO: !!\n",
    "    'virtual_sensor_positions': [\n",
    "        {'x': 0.0, 'y': 0.0, 'z': 0.0, 'name': 'Sensor1'},\n",
    "        {'x': 1.0, 'y': 0.0, 'z': 0.0, 'name': 'Sensor2'},\n",
    "        {'x': 1.78, 'y': 0.0, 'z': 26.91, 'name': 'Sensor3'},\n",
    "        {'x': -1.83, 'y': 0.0, 'z': 0.0, 'name': 'Sensor4'}\n",
    "        # Note: the real sensor positions are added automatically by the interface, so you don't need to specify them here.\n",
    "    ],\n",
    "    'full_field_results': False, # Set to True if you want full field results, the simulation will take longer and the results will be larger.\n",
    "    'uncertainty_quantification': False, # Set to True if you want uncertainty quantification, the simulation will take longer and the results will be larger.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Orchestrator class acts as the central controller for managing the entire digital twin simulation workflow. It handles configuration, setup, execution, and post-processing of simulations based on the provided input parameters.<br>\n",
    "<br>\n",
    "Orchestrator initialization with respect to the given parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = Orchestrator(simulation_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your key to MKP's API to registers it with the Orchestrator instance for secure communication with the backend services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=input(\"\\nEnter the code to connect API: \").strip()\n",
    "orchestrator.set_api_key(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After verifying that the virtual sensor coordinates lie within the mesh domain, the simulation is executed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All virtual sensors are within the mesh domain.\n",
      "Info    : Reading '../../../use_cases/nibelungenbruecke_demonstrator_self_weight_fenicsxconcrete/input/models/mesh_3d 1.msh'...\n",
      "Info    : 2443 entities\n",
      "Info    : 2197 nodes\n",
      "Info    : 12920 elements\n",
      "Info    : Done reading '../../../use_cases/nibelungenbruecke_demonstrator_self_weight_fenicsxconcrete/input/models/mesh_3d 1.msh'\n",
      "Same model with the same parameters!!\n"
     ]
    }
   ],
   "source": [
    "orchestrator.load(simulation_parameters)\n",
    "results = orchestrator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The result at the chosen sensors are plotted below. The results can be downloaded from the path written below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator.plot_virtual_sensor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results is probably just a dictionary of values with the sensor names as keys and the values as lists of results at each time step. --> Ask!  Previous one?\n",
    "# The method should just be going over the keys defined as virtual sensors and plotting the results at those positions --> Ask!  Previous one?\n",
    "# Passing the parameters as a dictionary to the method is also acceptable if needed.    --> Not done!!\n",
    "# The option \"uncertainty_quantification\" is used to determine if the results should be plotted with uncertainty quantification or not.\n",
    "\n",
    "#dt.plot_results_at_virtual_sensors(results, uncertainty_quantification=simulation_parameters['uncertainty_quantification'])\n",
    "# The results file should be saved in an accessible path at the root, with metadata about the simulation and the results.\n",
    "#print(\"PATH TO RESULTS:\", dt.get_results_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot aswell a comparison between model response and real sensors when available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orchestrator.plot_results_at_real_sensors(results, uncertainty_quantification=simulation_parameters['uncertainty_quantification'])  # Plot the results, this can be done after the run or separately if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the digital twin simulation using the loaded model and parameters. This will simulate the bridge behavior based on the selected physics model (e.g., thermal or displacement) and input configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional results (only if run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-field response (3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full-field simulation results are currently available as files and can be downloaded from the specified paths.<br>\n",
    "Interactive visualization within the interface is not yet supported but will be introduced soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to full-field results:\n",
      "TransientThermal_1 -> h5py_path: ../../../use_cases/nibelungenbruecke_demonstrator_self_weight_fenicsxconcrete/output/paraview/Nibelungenbrücke_thermal.h5\n",
      "TransientThermal_1 -> xmdf_path: ../../../use_cases/nibelungenbruecke_demonstrator_self_weight_fenicsxconcrete/output/paraview/Nibelungenbrücke_thermal.xmdf\n"
     ]
    }
   ],
   "source": [
    "orchestrator.plot_full_field_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3D model results are generated by activating the \"paraview\" parameter in the simulation parameters, which will save the results as xdmf and h5 files.\n",
    "# The visualization can be done using pyvista, which is a wrapper around VTK that allows for easy 3D visualization in Python.\n",
    "# The results can be visualized using the plot_full_field_response method, which will load the results file and plot the full field response.\n",
    "# If implementing this as a method does not work, we can just use the pyvista library directly to load the results file and plot the full field response.\n",
    "# if simulation_parameters['full_field_results']:\n",
    "#    print(\"Full field results are enabled, plotting the full field response.\")\n",
    "#    dt.plot_full_field_response(results, uncertainty_quantification=simulation_parameters['uncertainty_quantification'])  # Plot the full field response, this should be done using pyvista and the saved results file.\n",
    "#    print(\"PATH TO FULL FIELD RESULTS:\", dt.get_full_field_results_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All virtual sensors are within the mesh domain.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "new_parameters = deepcopy(simulation_parameters)\n",
    "new_parameters['parameter_update'] = {'rho': 2800, 'E': 290000000000}\n",
    "\n",
    "orchestrator.load(new_parameters)\n",
    "#result2 = orchestrator.run()\n",
    "orchestrator.plot_virtual_sensor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All virtual sensors are within the mesh domain.\n",
      "Same model with the same parameters!!\n",
      "Third run result: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "new_parameters = deepcopy(orchestrator.simulation_parameters)\n",
    "new_parameters['virtual_sensor_positions'] = [\n",
    "    {'x': 1.78, 'y': 0.0, 'z': 26.91, 'name': 'Sensor1'},\n",
    "    {'x': -1.83, 'y': 0.0, 'z': 0.0, 'name': 'Sensor2'}\n",
    "]\n",
    "\n",
    "orchestrator.load(new_parameters)\n",
    "\n",
    "result3 = orchestrator.run()\n",
    "print(\"Third run result:\", result3)\n",
    "orchestrator.plot_virtual_sensor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model 'thermal_model' saved successfully.\n",
      "Info    : Reading '../../../use_cases/nibelungenbruecke_demonstrator_self_weight_fenicsxconcrete/input/models/mesh_3d 1.msh'...\n",
      "Info    : 2443 entities\n",
      "Info    : 2197 nodes\n",
      "Info    : 12920 elements\n",
      "Info    : Done reading '../../../use_cases/nibelungenbruecke_demonstrator_self_weight_fenicsxconcrete/input/models/mesh_3d 1.msh'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 96/4281 [00:32<24:46,  2.82it/s]"
     ]
    }
   ],
   "source": [
    "new_parameters['parameter_update'] = {'rho': 3000, 'E': 290000000000}\n",
    "result4 = orchestrator.run(new_parameters)\n",
    "print(\"Fourth run result:\", result4)\n",
    "orchestrator.plot_virtual_sensor_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result5 = orchestrator.run(new_parameters)\n",
    "print(\"Fifth run result:\", result5)\n",
    "orchestrator.plot_virtual_sensor_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(original_cwd)\n",
    "print(\"Working directory restored to:\", original_cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
