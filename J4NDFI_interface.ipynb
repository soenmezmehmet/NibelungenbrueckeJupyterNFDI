{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Simulation-Based Digital Twin: Nibelungenbrücke\n",
    "\n",
    "This notebook introduces an online simulation-based digital twin developed for the Nibelungenbrücke bridge. The orchestration system is designed to interact dynamically with the user by gathering key inputs; such as time, physical parameters, and spatial positions to perform real-time simulations of the bridge structure.\n",
    "\n",
    "The simulations are powered by the FenicSXConcrete package and support both thermomechanical and structural deflection analyses. This framework enables physics-based modeling and continuous digital monitoring of the bridge's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Please run the code below once to install the packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install git+https://github.com/BAMresearch/FenicsXConcrete pint gmsh pytest jsonschema pandas pyproj tqdm pvlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "original_cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "original_cwd = os.getcwd()\n",
    "root_dir = os.getcwd()\n",
    "orchestrator_dir = os.path.join(root_dir, 'nibelungenbruecke', 'scripts', 'digital_twin_orchestrator')\n",
    "os.chdir(orchestrator_dir)\n",
    "sys.path.insert(0, root_dir)\n",
    "\n",
    "from nibelungenbruecke.scripts.digital_twin_orchestrator.orchestrator import Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of input parameters\n",
    "\n",
    "Define here the parameters with which you want to generate the simulation. The options are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_parameters = {\n",
    "    'simulation_name': 'TestSimulation',\n",
    "    'model': 'TransientThermal_1',\n",
    "    'start_time': '2023-08-11T08:00:00Z',\n",
    "    'end_time': '2023-09-11T08:01:00Z',\n",
    "    'time_step': '10min',\n",
    "    'virtual_sensor_positions': [\n",
    "        {'x': 0.0, 'y': 0.0, 'z': 0.0, 'name': 'Sensor1'},\n",
    "        {'x': 1.0, 'y': 0.0, 'z': 0.0, 'name': 'Sensor2'},\n",
    "        {'x': 1.78, 'y': 0.0, 'z': 26.91, 'name': 'Sensor3'},\n",
    "        {'x': -1.83, 'y': 0.0, 'z': 0.0, 'name': 'Sensor4'}\n",
    "        # Note: the real sensor positions are added automatically by the interface, so you don't need to specify them here.\n",
    "    ],\n",
    "    'full_field_results': False, # Set to True if you want full field results, the simulation will take longer and the results will be larger.\n",
    "    'uncertainty_quantification': False, # Set to True if you want uncertainty quantification, the simulation will take longer and the results will be larger.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orchestrator initialization with respect to the given parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = Orchestrator(simulation_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your key to MKP's API, to use the real data from the Nibelungenbrücke monitoring system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=input(\"\\nEnter the code to connect API: \").strip()\n",
    "orchestrator.set_api_key(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator.load(simulation_parameters) # Here we first load and then run, so that we can check the inputs before running the simulation and throw an error if something is wrong.\n",
    "results = orchestrator.run() # The plotting should be separated from the run, so that we can run the simulation without plotting if we want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator.plot_results_at_virtual_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result at the chosen sensors are plotted below. The results can be downloaded from the path written below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results is probably just a dictionary of values with the sensor names as keys and the values as lists of results at each time step.\n",
    "# The method should just be going over the keys defined as virtual sensors and plotting the results at those positions\n",
    "# Passing the parameters as a dictionary to the method is also acceptable if needed.\n",
    "# The option \"uncertainty_quantification\" is used to determine if the results should be plotted with uncertainty quantification or not.\n",
    "\n",
    "#dt.plot_results_at_virtual_sensors(results, uncertainty_quantification=simulation_parameters['uncertainty_quantification'])\n",
    "# The results file should be saved in an accessible path at the root, with metadata about the simulation and the results.\n",
    "#print(\"PATH TO RESULTS:\", dt.get_results_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot aswell a comparison between model response and real sensors when available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orchestrator.plot_results_at_real_sensors(results, uncertainty_quantification=simulation_parameters['uncertainty_quantification'])  # Plot the results, this can be done after the run or separately if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the digital twin simulation using the loaded model and parameters. This will simulate the bridge behavior based on the selected physics model (e.g., thermal or displacement) and input configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional results (only if run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-field response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is the 3D model full field response. The corresponding files can be downloaded from the given path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3D model results are generated by activating the \"paraview\" parameter in the simulation parameters, which will save the results as xdmf and h5 files.\n",
    "# The visualization can be done using pyvista, which is a wrapper around VTK that allows for easy 3D visualization in Python.\n",
    "# The results can be visualized using the plot_full_field_response method, which will load the results file and plot the full field response.\n",
    "# If implementing this as a method does not work, we can just use the pyvista library directly to load the results file and plot the full field response.\n",
    "# if simulation_parameters['full_field_results']:\n",
    "#    print(\"Full field results are enabled, plotting the full field response.\")\n",
    "#    dt.plot_full_field_response(results, uncertainty_quantification=simulation_parameters['uncertainty_quantification'])  # Plot the full field response, this should be done using pyvista and the saved results file.\n",
    "#    print(\"PATH TO FULL FIELD RESULTS:\", dt.get_full_field_results_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters and reload\n",
    "new_parameters = simulation_parameters.copy()\n",
    "new_parameters['parameter_update'] = {'rho': 2900, 'E': 290000000000}\n",
    "\n",
    "orchestrator.load(new_parameters)\n",
    "result2 = orchestrator.run()\n",
    "print(\"Second run result:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_sensor_positions = [\n",
    "        {'x': 1.78, 'y': 0.0, 'z': 26.91, 'name': 'Sensor1'},\n",
    "        {'x': -1.83, 'y': 0.0, 'z': 0.0, 'name': 'Sensor2'}\n",
    "        # Note: the real sensor positions are added automatcally by the interface, so you don't need to specify them here.\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator.simulation_parameters[\"virtual_sensor_positions\"] = virtual_sensor_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#orchestrator.plot_results_at_virtual_sensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(original_cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
